# Pose & Emotion Detector

Real-time human **pose** and **emotion detection** system using:
- **MediaPipe & custom PyTorch & Onnx models** for posture classification
- **YOLO** and **custom emotion models** for facial expression recognition

> ğŸš€ Built for real-time webcam input, but easily extendable to images and videos!

---

## ğŸ›  Features

- ğŸ“¸ **Pose Detection**: Classify human body posture as `upright` or `hunchback`.
- ğŸ˜„ **Emotion Recognition**: Detect facial emotions (`Happy`, `Sad`, `Angry`, `Neutral`, `Fear`, `Surprise`).
- ğŸ”¥ **Fast Inference**: Uses ONNX Runtime and quantized models for optimized performance.
- ğŸ¯ **YOLOv11 Face Detection**: Accurate and efficient face detection.
- ğŸ–¥ï¸ **Real-Time Webcam Feed**: Streamlined pipeline for live analysis.
- ğŸ§© **Modular Code**: Easily swap detectors (YOLO, Haar Cascade, ONNX) and classification models.

---

## ğŸ“‚ Project Structure
**ğŸ”’ checkpoints**/ â€“  Saved models

**âš™ï¸ utils/** â€“  Core components

Â Â Â Â â€¢ emotion_model_api.py â€“ API for Emotion detection via webcam
    
Â Â Â Â â€¢ emotion_pose_model.py â€“ Combined real-time pose + emotion detection
    
Â Â Â Â â€¢ haar_detector.py â€“ Haar cascade-based face detection
    
Â Â Â Â â€¢ pose_model_api.py â€“ API for Posture detection via webcam 
    
Â Â Â Â â€¢ yolo_detector.py â€“ YOLOv8-based face detection

**ğŸ‹ï¸ train.py** â€“  Script to train the posture classification model

**ğŸ§  train_emotion.py** â€“  Script to train the emotion classification model

**ğŸ“Š evaluate.py** â€“  Evaluate model performance on test data

**ğŸ“¦ requirements.txt** â€“  Python dependency list

**ğŸ“– README.md** â€“  Project documentation (you are here!)


---

## âš™ï¸ Installation

1. **Clone the repository:**

```bash
git clone https://github.com/Yogesh-45/pose-emotion-detector.git
cd pose-emotion-detector
```

2. **Setup Python Environment:**

```
conda create -n pose_emotion python=3.10
conda activate pose_emotion

pip install -r requirements.txt
```

## ğŸš€ Usage

1. **Real-time Pose and Emotion Detection (Webcam)**
```
python utils/emotion_pose_model.py
```
This script:

Classifies pose as **Upright** or **Hunchback**.

Detects dominant Emotion.

Displays bounding boxes and labels.

Displays real-time cpu & memory usage.

2. **Run via C++ Application (Pybind11)**
You can also use C++ + Pybind11 to run Python emotion detection:
```
cd cpp
mkdir build && cd build
cmake ..
cmake --build . --config Release
.\Release\main.exe
```
âœ… This shows how to embed Python models inside a native C++ application.

**ğŸ“Œ Requirements for C++ Integration**
To build and run the C++ integration successfully, ensure the following:

âœ… CMake â‰¥ 3.14 is installed

âœ… Visual Studio Build Tools (Windows) or g++ (Linux/macOS)

âœ… Python 3.10+ installed

âœ… Python development headers are available
(e.g., via conda install python-dev or choosing Python with dev headers during install)

âœ… pybind11 source code is cloned inside your repo at:

```
cpp/external/pybind11
```
You can get it via:

```
git clone https://github.com/pybind/pybind11.git cpp/external/pybind11
```

âœ… Your emotion_api.py is in the correct path (./utils or adjusted accordingly)

âœ… Youâ€™ve added sys.path.insert(0, "<path-to-emotion_api>") in both main.cpp and bindings.cpp


## ğŸ§  Technologies Used

| Component           | Library / Framework                         |
|---------------------|---------------------------------------------|
| Face Detection      | YOLOv11, Haar Cascade                        |
| Pose Estimation      | MediaPipe Pose, Custom Classifier           |
| Emotion Detection   | DeepFace (initially), Custom PyTorch model  |
| Optimization         | ONNX, FP16 quantization                     |
| Real-Time Inference | OpenCV, PyTorch                             |
| C++ Integration      | pybind11, CMake                             |


## ğŸ™Œ Acknowledgments
[PyTorch](https://pytorch.org/)

[OpenCV](https://opencv.org/)

[YOLO Face](https://github.com/akanametov/yolo-face)

[ONNX Runtime](https://github.com/microsoft/onnxruntime)

[MediaPipe](https://ai.google.dev/edge/mediapipe/solutions/guide)

[Pybind11](https://github.com/pybind/pybind11)

## ğŸ“„ License
This project is licensed under the MIT License.

## ğŸ‘¤ Author
**Yogesh Dhyani**
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=flat-square&logo=linkedin)](https://www.linkedin.com/in/yogesh-dhyani-b0a1511ab/)

â­ If you find this project helpful, give it a star and share it!




